{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this service does: Generates a summary of a document.\n",
    "\n",
    "Summarization is a combination of generative Large Language models and task-optimized encoder models. The service provides summarization solutions for plain texts, conversations, and native documents. \n",
    "\n",
    "Supported Input:\n",
    "- Text summarization only accepts plain text blocks. \n",
    "- Conversation summarization accepts conversational input, including various speech audio signals. \n",
    "- Native document summarization accepts documents in their native formats, such as Word, PDF, or plain text. \n",
    "\n",
    "Prerequisites:\n",
    "Make sure you have a Language resource deployed on Azure. If that's the case, you can fetch your credentials -- Azure Language endpoint and key -- on Azure Portal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text summarization is done through a specialised method (\"begin_abstract_summary\") of the TextAnalyticsClient class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_LANGUAGE_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_LANGUAGE_KEY\")\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is passed as a list of documents. Each document can be passed as a string in the list or as a list of DetectLanguageInput or TextDocumentInput, or a dict-like representation of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\n",
    "        \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, \"\n",
    "        \"human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive \"\n",
    "        \"Services, I have been working with a team of amazing scientists and engineers to turn this quest into a \"\n",
    "        \"reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of \"\n",
    "        \"human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the \"\n",
    "        \"intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint \"\n",
    "        \"representation to create more powerful AI that can speak, hear, see, and understand humans better. \"\n",
    "        \"We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, \"\n",
    "        \"spanning modalities and languages. The goal is to have pretrained models that can jointly learn \"\n",
    "        \"representations to support a broad range of downstream AI tasks, much in the way humans do today. \"\n",
    "        \"Over the past five years, we have achieved human performance on benchmarks in conversational speech \"\n",
    "        \"recognition, machine translation, conversational question answering, machine reading comprehension, \"\n",
    "        \"and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious \"\n",
    "        \"aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that \"\n",
    "        \"is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational \"\n",
    "        \"component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 available mathods for summarization: extractive and abstractive. The first one returns the most salient sentences from the original document that correspond to the main idea of the text. The second method returns a summary of the whole document using phrases and synonyms that were not necessarily present in the original document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell bellow to get an extractive summary of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "At the intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint representation to create more powerful AI that can speak, hear, see, and understand humans better. We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, spanning modalities and languages. The goal is to have pretrained models that can jointly learn representations to support a broad range of downstream AI tasks, much in the way humans do today.\n"
     ]
    }
   ],
   "source": [
    "poller = text_analytics_client.begin_extract_summary(document)\n",
    "extract_summary_results = poller.result()\n",
    "for result in extract_summary_results:\n",
    "    if result.kind == \"ExtractiveSummarization\":\n",
    "        print(\"Summary extracted: \\n{}\".format(\n",
    "             \" \".join([sentence.text for sentence in result.sentences]))\n",
    "        )\n",
    "    elif result.is_error is True:\n",
    "        print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "            result.error.code, result.error.message\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell bellow to get an abstractive summary of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries abstracted:\n",
      "The Chief Technology Officer of Azure AI Cognitive Services discusses Microsoft's commitment to advancing AI by integrating monolingual text, audio or visual signals, and multilingual capabilities, termed as the XYZ-code. This approach aims to create AI that can better understand humans across different domains and languages. Through their efforts, Microsoft has achieved human-level performance on key benchmarks in speech recognition, machine translation, conversational question answering, reading comprehension, and image captioning. The ultimate goal is to develop pretrained models that can learn from multiple modalities and languages, akin to human learning, and incorporate external knowledge sources for downstream AI tasks. This progress is seen as a stepping stone towards a significant leap in AI capabilities, with a focus on multisensory and multilingual learning. The XYZ-code is central to this vision, promising a more holistic and human-centric AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poller = text_analytics_client.begin_abstract_summary(document)\n",
    "\n",
    "abstract_summary_results = poller.result()\n",
    "\n",
    "for result in abstract_summary_results:\n",
    "    if result.kind == \"AbstractiveSummarization\":\n",
    "        print(\"Summaries abstracted:\")\n",
    "        [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "    elif result.is_error is True:\n",
    "        print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "            result.error.code, result.error.message\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
