{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ©ºðŸ“Šâœ¨ Text Analytics for Health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure AI Language Text Analytics for Health is a cloud-based API service that uses machine learning to extract and label relevant medical information from unstructured texts like doctor's notes, discharge summaries, clinical documents, and electronic health records. This service is designed to help healthcare providers improve health outcomes by analyzing text data for insights.\n",
    "\n",
    "Its documentation can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/language-service/text-analytics-for-health/overview?tabs=ner). \n",
    "\n",
    "With Azure AI Language Text Analytics for Health, you can:\n",
    "\n",
    "- **Named Entity Recognition**: Identify and categorize medical entities such as \n",
    "    - *Medications*: Names of drugs, dosages, and forms (e.g., tablets, injections).\n",
    "    - *Conditions*: Medical conditions, diseases, symptoms, and diagnoses.\n",
    "    - *Procedures*: Medical procedures, surgeries, and treatments.\n",
    "    - *Anatomical Terms*: Parts of the body, organs, and tissues.\n",
    "    - *Lab Tests*: Names of laboratory tests and their results.\n",
    "    - *Medical Devices*: Equipment and devices used in medical treatments.\n",
    "    - *Healthcare Providers*: Names and roles of healthcare professionals (e.g., doctors, nurses).\n",
    "    - *Patient Information*: Demographic details such as age, gender, and ethnicity.\n",
    "    - *Clinical Events*: Events related to patient care, such as hospital admissions and discharges.\n",
    "- **Relation Extraction**: Determine relationships between entities, such as dosage and medication.\n",
    "- **Entity Linking**: Link entities to standardized medical vocabularies like UMLS.\n",
    "- **Assertion Detection**: Identify whether entities are present, absent, or conditional.\n",
    "- **Social Determinants of Health (SDOH) Extraction**: Extract mentions of social factors affecting health, such as living conditions and ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure Python is installed. \n",
    "2. Create a virtual environment and activate it. \n",
    "3. Install the dependencies specified in requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-textanalytics==5.2.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: azure-identity in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.21.0)\n",
      "Requirement already satisfied: azure-core in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.33.0)\n",
      "Requirement already satisfied: msrest>=0.7.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (4.13.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-identity->-r requirements.txt (line 2)) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-identity->-r requirements.txt (line 2)) (1.32.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-identity->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-core->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from azure-core->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity->-r requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->-r requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/nicograssetto/Documents/GitHub/ai-language-notebooks/.venv/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.7.0->azure-ai-textanalytics==5.2.0->-r requirements.txt (line 1)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Deploy the necessary services by clicking on the Deploy button in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FNicoGrassetto%2Fai-language-notebooks%2Fmain%2Ftext-analytics-for-health%2Fdeplo.json\" target=\"_blank\">\n",
    "    <img src=\"deploytoazure.svg\" alt=\"Button\" style=\"width:200px;height:auto;\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Healthcare Entities and Identify Relationships in Document Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "\n",
    "    documents = [\n",
    "        \"RECORD #333582770390100 | MH | 85986313 | | 054351 | 2/14/2001 12:00:00 AM | \\\n",
    "        CORONARY ARTERY DISEASE | Signed | DIS | Admission Date: 5/22/2001 \\\n",
    "        Report Status: Signed Discharge Date: 4/24/2001 ADMISSION DIAGNOSIS: \\\n",
    "        CORONARY ARTERY DISEASE. HISTORY OF PRESENT ILLNESS: \\\n",
    "        The patient is a 54-year-old gentleman with a history of progressive angina over the past several months. \\\n",
    "        The patient had a cardiac catheterization in July of this year revealing total occlusion of the RCA and \\\n",
    "        50% left main disease , with a strong family history of coronary artery disease with a brother dying at \\\n",
    "        the age of 52 from a myocardial infarction and another brother who is status post coronary artery bypass grafting. \\\n",
    "        The patient had a stress echocardiogram done on July , 2001 , which showed no wall motion abnormalities ,\\\n",
    "        but this was a difficult study due to body habitus. The patient went for six minutes with minimal ST depressions \\\n",
    "        in the anterior lateral leads , thought due to fatigue and wrist pain , his anginal equivalent. Due to the patient's \\\n",
    "        increased symptoms and family history and history left main disease with total occasional of his RCA was referred \\\n",
    "        for revascularization with open heart surgery.\"\n",
    "    ]\n",
    "\n",
    "    poller = text_analytics_client.begin_analyze_healthcare_entities(documents)\n",
    "\n",
    "    try:\n",
    "        poller.cancel()\n",
    "    except HttpResponseError as e:\n",
    "        # If the operation has already reached a terminal state it cannot be cancelled.\n",
    "        print(e)\n",
    "\n",
    "    else:\n",
    "        print(\"Healthcare entities analysis was successfully cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Long-Running Operation for Comprehensive Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FILE: sample_analyze_healthcare_action.py\n",
    "\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to submit a collection of text documents for analysis, which uses the\n",
    "    AnalyzeHealthcareEntitiesAction (plus FHIR feature) and RecognizePiiEntitiesAction to recognize healthcare entities,\n",
    "    along with any PII entities.\n",
    "    The response will contain results from each of the individual actions specified in the request.\n",
    "\n",
    "USAGE:\n",
    "    python sample_analyze_healthcare_action.py\n",
    "\n",
    "    Set the environment variables with your own values before running the sample:\n",
    "    1) AZURE_LANGUAGE_ENDPOINT - the endpoint to your Language resource.\n",
    "    2) AZURE_LANGUAGE_KEY - your Language subscription key\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sample_analyze_healthcare_action() -> None:\n",
    "    import os\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import (\n",
    "        TextAnalyticsClient,\n",
    "        AnalyzeHealthcareEntitiesAction,\n",
    "        RecognizePiiEntitiesAction,\n",
    "    )\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "\n",
    "    documents = [\n",
    "        \"\"\"\n",
    "        Patient needs to take 100 mg of ibuprofen, and 3 mg of potassium. Also needs to take\n",
    "        10 mg of Zocor.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        Patient needs to take 50 mg of ibuprofen, and 2 mg of Coumadin.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    poller = text_analytics_client.begin_analyze_actions(\n",
    "        documents,\n",
    "        display_name=\"Sample Text Analysis\",\n",
    "        actions=[\n",
    "            AnalyzeHealthcareEntitiesAction(),\n",
    "            RecognizePiiEntitiesAction(domain_filter=\"phi\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    document_results = poller.result()\n",
    "    for doc, action_results in zip(documents, document_results):\n",
    "        print(f\"\\nDocument text: {doc}\")\n",
    "        for result in action_results:\n",
    "            if result.kind == \"Healthcare\":\n",
    "                print(\"...Results of Analyze Healthcare Entities Action:\")\n",
    "                for entity in result.entities:\n",
    "                    print(f\"Entity: {entity.text}\")\n",
    "                    print(f\"...Normalized Text: {entity.normalized_text}\")\n",
    "                    print(f\"...Category: {entity.category}\")\n",
    "                    print(f\"...Subcategory: {entity.subcategory}\")\n",
    "                    print(f\"...Offset: {entity.offset}\")\n",
    "                    print(f\"...Confidence score: {entity.confidence_score}\")\n",
    "                    if entity.data_sources is not None:\n",
    "                        print(\"...Data Sources:\")\n",
    "                        for data_source in entity.data_sources:\n",
    "                            print(f\"......Entity ID: {data_source.entity_id}\")\n",
    "                            print(f\"......Name: {data_source.name}\")\n",
    "                    if entity.assertion is not None:\n",
    "                        print(\"...Assertion:\")\n",
    "                        print(f\"......Conditionality: {entity.assertion.conditionality}\")\n",
    "                        print(f\"......Certainty: {entity.assertion.certainty}\")\n",
    "                        print(f\"......Association: {entity.assertion.association}\")\n",
    "                for relation in result.entity_relations:\n",
    "                    print(f\"Relation of type: {relation.relation_type} has the following roles\")\n",
    "                    for role in relation.roles:\n",
    "                        print(f\"...Role '{role.name}' with entity '{role.entity.text}'\")\n",
    "\n",
    "            elif result.kind == \"PiiEntityRecognition\":\n",
    "                print(\"Results of Recognize PII Entities action:\")\n",
    "                for pii_entity in result.entities:\n",
    "                    print(f\"......Entity: {pii_entity.text}\")\n",
    "                    print(f\".........Category: {pii_entity.category}\")\n",
    "                    print(f\".........Confidence Score: {pii_entity.confidence_score}\")\n",
    "\n",
    "            elif result.is_error is True:\n",
    "                print(f\"...Is an error with code '{result.error.code}' and message '{result.error.message}'\")\n",
    "\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_analyze_healthcare_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Healthcare Entities in Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License. See License.txt in the project root for\n",
    "# license information.\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "FILE: sample_analyze_healthcare_entities.py\n",
    "\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to detect healthcare entities in a batch of documents.\n",
    "\n",
    "    In this sample we will be a newly-hired engineer working in a pharmacy. We are going to\n",
    "    comb through all of the prescriptions our pharmacy has fulfilled so we can catalog how\n",
    "    much inventory we have.\n",
    "\n",
    "USAGE:\n",
    "    python sample_analyze_healthcare_entities.py\n",
    "\n",
    "    Set the environment variables with your own values before running the sample:\n",
    "    1) AZURE_LANGUAGE_ENDPOINT - the endpoint to your Language resource.\n",
    "    2) AZURE_LANGUAGE_KEY - your Language subscription key\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sample_analyze_healthcare_entities() -> None:\n",
    "\n",
    "    print(\n",
    "        \"In this sample we will be combing through the prescriptions our pharmacy has fulfilled \"\n",
    "        \"so we can catalog how much inventory we have\"\n",
    "    )\n",
    "    print(\n",
    "        \"We start out with a list of prescription documents.\"\n",
    "    )\n",
    "\n",
    "    # [START analyze_healthcare_entities]\n",
    "    import os\n",
    "    import typing\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import TextAnalyticsClient, HealthcareEntityRelation\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "\n",
    "    documents = [\n",
    "        \"\"\"\n",
    "        Patient needs to take 100 mg of ibuprofen, and 3 mg of potassium. Also needs to take\n",
    "        10 mg of Zocor.\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        Patient needs to take 50 mg of ibuprofen, and 2 mg of Coumadin.\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    poller = text_analytics_client.begin_analyze_healthcare_entities(documents)\n",
    "    result = poller.result()\n",
    "\n",
    "    docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    print(\"Let's first visualize the outputted healthcare result:\")\n",
    "    for doc in docs:\n",
    "        for entity in doc.entities:\n",
    "            print(f\"Entity: {entity.text}\")\n",
    "            print(f\"...Normalized Text: {entity.normalized_text}\")\n",
    "            print(f\"...Category: {entity.category}\")\n",
    "            print(f\"...Subcategory: {entity.subcategory}\")\n",
    "            print(f\"...Offset: {entity.offset}\")\n",
    "            print(f\"...Confidence score: {entity.confidence_score}\")\n",
    "            if entity.data_sources is not None:\n",
    "                print(\"...Data Sources:\")\n",
    "                for data_source in entity.data_sources:\n",
    "                    print(f\"......Entity ID: {data_source.entity_id}\")\n",
    "                    print(f\"......Name: {data_source.name}\")\n",
    "            if entity.assertion is not None:\n",
    "                print(\"...Assertion:\")\n",
    "                print(f\"......Conditionality: {entity.assertion.conditionality}\")\n",
    "                print(f\"......Certainty: {entity.assertion.certainty}\")\n",
    "                print(f\"......Association: {entity.assertion.association}\")\n",
    "        for relation in doc.entity_relations:\n",
    "            print(f\"Relation of type: {relation.relation_type} has the following roles\")\n",
    "            for role in relation.roles:\n",
    "                print(f\"...Role '{role.name}' with entity '{role.entity.text}'\")\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "    print(\"Now, let's get all of medication dosage relations from the documents\")\n",
    "    dosage_of_medication_relations = [\n",
    "        entity_relation\n",
    "        for doc in docs\n",
    "        for entity_relation in doc.entity_relations if entity_relation.relation_type == HealthcareEntityRelation.DOSAGE_OF_MEDICATION\n",
    "    ]\n",
    "    # [END analyze_healthcare_entities]\n",
    "\n",
    "    print(\n",
    "        \"Now, I will create a dictionary of medication to total dosage. \"\n",
    "        \"I will use a regex to extract the dosage amount. For simplicity sake, I will assume \"\n",
    "        \"all dosages are represented with numbers and have mg unit.\"\n",
    "    )\n",
    "    import re\n",
    "    from collections import defaultdict\n",
    "\n",
    "    medication_to_dosage: typing.Dict[str, int] = defaultdict(int)\n",
    "\n",
    "    for relation in dosage_of_medication_relations:\n",
    "        # The DosageOfMedication relation should only contain the dosage and medication roles\n",
    "\n",
    "        dosage_role = next(iter(filter(lambda x: x.name == \"Dosage\", relation.roles)))\n",
    "        medication_role = next(iter(filter(lambda x: x.name == \"Medication\", relation.roles)))\n",
    "\n",
    "        try:\n",
    "            dosage_value = int(re.findall(r\"\\d+\", dosage_role.entity.text)[0]) # we find the numbers in the dosage\n",
    "            medication_to_dosage[medication_role.entity.text] += dosage_value\n",
    "        except StopIteration:\n",
    "            # Error handling for if there's no dosage in numbers.\n",
    "            pass\n",
    "\n",
    "    for medication, dosage in medication_to_dosage.items():\n",
    "        print(\"We have fulfilled '{}' total mg of '{}'\".format(\n",
    "            dosage, medication\n",
    "        ))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_analyze_healthcare_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License. See License.txt in the project root for\n",
    "# license information.\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "FILE: sample_model_version.py\n",
    "\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to set the model_version for pre-built Text Analytics models.\n",
    "    Recognize entities is used in this sample, but the concept applies generally to all pre-built Text Analytics models.\n",
    "\n",
    "    By default, model_version is set to \"latest\". This indicates that the latest generally available version\n",
    "    of the model will be used. Model versions are date based, e.g \"2021-06-01\".\n",
    "    See the documentation for a list of all model versions:\n",
    "    https://aka.ms/text-analytics-model-versioning\n",
    "\n",
    "USAGE:\n",
    "    python sample_model_version.py\n",
    "\n",
    "    Set the environment variables with your own values before running the sample:\n",
    "    1) AZURE_LANGUAGE_ENDPOINT - the endpoint to your Language resource.\n",
    "    2) AZURE_LANGUAGE_KEY - your Language subscription key\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sample_model_version() -> None:\n",
    "    print(\"--------------Choosing model_version sample--------------\")\n",
    "    import os\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import TextAnalyticsClient, RecognizeEntitiesAction\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "    documents = [\n",
    "        \"I work for Foo Company, and we hired Contoso for our annual founding ceremony. The food \\\n",
    "        was amazing and we all can't say enough good words about the quality and the level of service.\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\nSetting model_version='latest' with recognize_entities\")\n",
    "    result = text_analytics_client.recognize_entities(documents, model_version=\"latest\")\n",
    "    result = [review for review in result if not review.is_error]\n",
    "\n",
    "    print(\"...Results of Recognize Entities:\")\n",
    "    for review in result:\n",
    "        for entity in review.entities:\n",
    "            print(f\"......Entity '{entity.text}' has category '{entity.category}'\")\n",
    "\n",
    "    print(\"\\nSetting model_version='latest' with recognize entities action in begin_analyze_actions\")\n",
    "    poller = text_analytics_client.begin_analyze_actions(\n",
    "        documents,\n",
    "        actions=[\n",
    "            RecognizeEntitiesAction(model_version=\"latest\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"...Results of Recognize Entities Action:\")\n",
    "    document_results = poller.result()\n",
    "    for action_results in document_results:\n",
    "        action_result = action_results[0]\n",
    "        if action_result.kind == \"EntityRecognition\":\n",
    "            for entity in action_result.entities:\n",
    "                print(f\"......Entity '{entity.text}' has category '{entity.category}'\")\n",
    "        elif action_result.is_error is True:\n",
    "            print(\"......Is an error with code '{}' and message '{}'\".format(\n",
    "                action_result.error.code, action_result.error.message\n",
    "            ))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_model_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from azure.identity import DefaultAzureCredential\n",
    "# from azure.ai.textanalytics import TextAnalyticsClient\n",
    "# import os\n",
    "# # Use DefaultAzureCredential for managed identity authentication\n",
    "# credential = DefaultAzureCredential()\n",
    "# endpoint = os.environ.get('LANGUAGE_ENDPOINT')\n",
    "# # Create the Text Analytics client\n",
    "# client = TextAnalyticsClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment '.venv (Python 3.12.9)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# # Authenticate the client using your key and endpoint \n",
    "# def authenticate_client():\n",
    "#     ta_credential = AzureKeyCredential(key)\n",
    "#     text_analytics_client = TextAnalyticsClient(\n",
    "#             endpoint=endpoint, \n",
    "#             credential=ta_credential)\n",
    "#     return text_analytics_client\n",
    "\n",
    "# client = authenticate_client()\n",
    "\n",
    "# # Example function for extracting information from healthcare-related text \n",
    "# def health_example(client):\n",
    "#     documents = [\n",
    "#         \"\"\"\n",
    "#         Patient needs to take 50 mg of ibuprofen.\n",
    "#         \"\"\"\n",
    "#     ]\n",
    "\n",
    "#     poller = client.begin_analyze_healthcare_entities(documents)\n",
    "#     result = poller.result()\n",
    "\n",
    "#     docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "#     for idx, doc in enumerate(docs):\n",
    "#         for entity in doc.entities:\n",
    "#             print(\"Entity: {}\".format(entity.text))\n",
    "#             print(\"...Normalized Text: {}\".format(entity.normalized_text))\n",
    "#             print(\"...Category: {}\".format(entity.category))\n",
    "#             print(\"...Subcategory: {}\".format(entity.subcategory))\n",
    "#             print(\"...Offset: {}\".format(entity.offset))\n",
    "#             print(\"...Confidence score: {}\".format(entity.confidence_score))\n",
    "#         for relation in doc.entity_relations:\n",
    "#             print(\"Relation of type: {} has the following roles\".format(relation.relation_type))\n",
    "#             for role in relation.roles:\n",
    "#                 print(\"...Role '{}' with entity '{}'\".format(role.name, role.entity.text))\n",
    "#         print(\"------------------------------------------\")\n",
    "# health_example(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
